import os
import cv2
import numpy as np
from pathlib import Path
from typing import List, Union, Optional
import torch
from PIL import Image
import moviepy.editor as mp

class VideoProcessor:
    """
    Utility class for processing video frames generated by Mochi-1
    """
    def __init__(self):
        """Initialize the VideoProcessor class with GPU capabilities"""
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        self.use_gpu = torch.cuda.is_available()
        
        if self.use_gpu:
            # Enable GPU acceleration for OpenCV if CUDA is available in the OpenCV build
            # Check if GPU acceleration is available in OpenCV
            cv_build_info = cv2.getBuildInformation()
            self.opencv_gpu = "CUDA" in cv_build_info
            if self.opencv_gpu:
                print("OpenCV with CUDA support detected. GPU acceleration enabled for video processing.")
            else:
                print("OpenCV without CUDA support. Using PyTorch GPU acceleration where possible.")
    
    def frames_to_video(
        self, 
        frames: List[Union[np.ndarray, torch.Tensor, Image.Image]], 
        output_path: Union[str, Path], 
        fps: int = 24,
        audio_path: Optional[Union[str, Path]] = None
    ) -> Path:
        """
        Convert a list of frames to a video file with GPU acceleration when possible
        
        Args:
            frames: List of frames (as numpy arrays, PyTorch tensors, or PIL Images)
            output_path: Path to save the output video
            fps: Frames per second
            audio_path: Optional path to an audio file to add to the video
            
        Returns:
            Path to the output video
        """
        output_path = Path(output_path)
        os.makedirs(output_path.parent, exist_ok=True)
        
        # Ensure all frames are numpy arrays
        np_frames = []
        for frame in frames:
            if isinstance(frame, torch.Tensor):
                # Handle PyTorch tensors efficiently with GPU
                if frame.device.type != 'cpu' and self.use_gpu:
                    # If tensor is on GPU and we have GPU, process it there
                    if frame.shape[0] == 3:  # Channel-first format
                        frame = frame.permute(1, 2, 0)
                    frame = (frame * 255).clamp(0, 255).to(torch.uint8)
                    frame = frame.cpu().numpy()
                else:
                    # Move to CPU for processing
                    frame = frame.cpu().numpy()
                    # Convert from CxHxW to HxWxC and scale to 0-255
                    if frame.shape[0] == 3:  # Channel-first format
                        frame = frame.transpose(1, 2, 0)
                    frame = (frame * 255).astype(np.uint8)
            elif isinstance(frame, Image.Image):
                frame = np.array(frame)
            
            np_frames.append(frame)
        
        # Get dimensions from the first frame
        height, width = np_frames[0].shape[:2]
        
        # Create temporary file for video without audio
        temp_path = output_path.with_suffix('.temp.mp4')
        
        # Create video writer
        fourcc = cv2.VideoWriter_fourcc(*'mp4v')
        out = cv2.VideoWriter(str(temp_path), fourcc, fps, (width, height))
        
        # Process frames in batches for better efficiency
        batch_size = 10  # Process 10 frames at a time
        for i in range(0, len(np_frames), batch_size):
            batch_frames = np_frames[i:i+batch_size]
            
            # Process each frame in the batch
            for frame in batch_frames:
                # Convert frame to BGR if it's RGB
                if frame.shape[2] == 3:  # RGB
                    frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)
                out.write(frame)
        
        out.release()
        
        # Add audio if provided
        if audio_path:
            video = mp.VideoFileClip(str(temp_path))
            audio = mp.AudioFileClip(str(audio_path))
            
            # If audio is longer than video, trim it
            if audio.duration > video.duration:
                audio = audio.subclip(0, video.duration)
            
            # Set audio
            final_video = video.set_audio(audio)
            final_video.write_videofile(str(output_path), codec='libx264', audio_codec='aac')
            
            # Clean up
            video.close()
            audio.close()
            os.remove(temp_path)
        else:
            # If no audio, just rename the temp file
            os.rename(temp_path, output_path)
        
        if self.use_gpu:
            # Clear GPU memory
            torch.cuda.empty_cache()
            
        return output_path
    
    def enhance_frames(self, frames: List[np.ndarray]) -> List[np.ndarray]:
        """
        Apply post-processing enhancements to generated frames using GPU acceleration when possible
        
        Args:
            frames: List of frames as numpy arrays
            
        Returns:
            List of enhanced frames
        """
        enhanced_frames = []
        
        # Use batch processing when possible
        if self.use_gpu:
            # Convert to torch tensor for GPU processing
            batch = []
            for frame in frames:
                # Convert to float32 tensor
                tensor_frame = torch.from_numpy(frame).float().to(self.device) / 255.0
                # Convert from HWC to CHW format
                if tensor_frame.shape[2] == 3:  # HWC format
                    tensor_frame = tensor_frame.permute(2, 0, 1)
                batch.append(tensor_frame)
            
            # Stack frames into a batch
            if batch:
                batch_tensor = torch.stack(batch)
                
                # Apply enhancements on GPU
                with torch.no_grad():
                    # Apply contrast and brightness adjustment
                    alpha = 1.2  # Contrast control
                    beta = 0.1    # Brightness control (in normalized space)
                    
                    # Apply contrast and brightness
                    enhanced_batch = alpha * batch_tensor + beta
                    enhanced_batch = torch.clamp(enhanced_batch, 0.0, 1.0)
                    
                    # Apply simple sharpening
                    # Define 3x3 sharpening kernel
                    kernel = torch.tensor([
                        [-1, -1, -1],
                        [-1,  9, -1],
                        [-1, -1, -1]
                    ], dtype=torch.float32, device=self.device).view(1, 1, 3, 3).repeat(3, 1, 1, 1)
                    
                    # Apply 2D convolution for sharpening
                    # We need padding=1 to maintain the same dimensions
                    enhanced_batch = torch.nn.functional.conv2d(
                        enhanced_batch,
                        kernel,
                        padding=1,
                        groups=3  # Apply separately to each channel
                    )
                    
                    # Ensure values are in valid range
                    enhanced_batch = torch.clamp(enhanced_batch, 0.0, 1.0)
                
                # Convert back to numpy arrays
                for enhanced in enhanced_batch:
                    # Convert from CHW to HWC format
                    enhanced = enhanced.permute(1, 2, 0)
                    # Convert to uint8
                    enhanced = (enhanced * 255).cpu().numpy().astype(np.uint8)
                    enhanced_frames.append(enhanced)
                
                # Free GPU memory
                torch.cuda.empty_cache()
        else:
            # CPU processing for each frame
            for frame in frames:
                # Apply simple enhancements for demonstration
                # Increase contrast
                alpha = 1.2  # Contrast control (1.0-3.0)
                beta = 10    # Brightness control (0-100)
                enhanced = cv2.convertScaleAbs(frame, alpha=alpha, beta=beta)
                
                # Apply slight sharpening
                kernel = np.array([[-1, -1, -1], 
                                   [-1,  9, -1], 
                                   [-1, -1, -1]])
                enhanced = cv2.filter2D(enhanced, -1, kernel)
                
                enhanced_frames.append(enhanced)
        
        return enhanced_frames 